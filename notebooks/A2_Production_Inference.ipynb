{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 2: Production Inference for Recipe Recommendation System\n",
        "\n",
        "## Project Overview\n",
        "This notebook demonstrates the inference pipeline for my PantryPal recipe recommendation system. After training our Learning-to-Rank model, we now show how to deploy it for real-time recommendations in production.\n",
        "\n",
        "## Business Application\n",
        "PantryPal users expect personalized recipe recommendations based on their interaction history. This notebook shows how we:\n",
        "- Load a trained model from disk\n",
        "- Fetch a user's interaction history from our app analytics\n",
        "- Generate personalized top-N recipe recommendations\n",
        "- Validate the recommendations for quality and relevance\n",
        "\n",
        "## Technical Implementation\n",
        "This notebook covers the complete inference workflow:\n",
        "- Environment setup (Colab-compatible)\n",
        "- Model and metadata loading from training artifacts\n",
        "- User interaction retrieval with `UserInteractionFetcher`\n",
        "- Real-time recipe scoring and ranking with `RecipeScorer`\n",
        "- System validation and performance checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment ready. Project root: /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/notebooks\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "# This cell configures the environment for both local development and Google Colab\n",
        "import sys, subprocess, os, pathlib\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "repo_root = pathlib.Path.cwd()\n",
        "\n",
        "# Install required packages for Colab environments\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                        \"lightgbm\", \"pandas\", \"numpy\", \"scikit-learn\"],\n",
        "                       check=False)\n",
        "    except Exception as e:\n",
        "        print(f\"pip install warning: {e}\")\n",
        "\n",
        "    # Clone the PantryPal ML repository if not already present\n",
        "    if not (repo_root / \"recipe_recommender\").exists():\n",
        "        subprocess.run([\"git\", \"-c\", \"advice.detachedHead=false\", \"clone\", \"-q\", \"https://github.com/marcel-qayoom-taylor/PantryPalML.git\"], check=True)\n",
        "        os.chdir(\"PantryPalML\")\n",
        "        repo_root = pathlib.Path.cwd()\n",
        "\n",
        "print(f\"Environment ready. Project root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Pipeline Configuration:\n",
            "Model directory: /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/recipe_recommender/output/hybrid_models\n",
            "Data output directory: /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/recipe_recommender/output\n"
          ]
        }
      ],
      "source": [
        "# Import Required Components for Inference Pipeline\n",
        "\n",
        "# Configuration management - same config used during training\n",
        "from recipe_recommender.config import get_ml_config\n",
        "\n",
        "# User interaction fetcher - retrieves user behavior from analytics events\n",
        "from recipe_recommender.etl.fetch_user_interactions import UserInteractionFetcher\n",
        "\n",
        "# Recipe scorer - loads trained model and generates recommendations\n",
        "from recipe_recommender.inference.recipe_scorer import RecipeScorer\n",
        "\n",
        "# Load configuration (ensures consistency with training pipeline)\n",
        "config = get_ml_config()\n",
        "print(\"Inference Pipeline Configuration:\")\n",
        "print(\"Model directory:\", config.model_dir)\n",
        "print(\"Data output directory:\", config.output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-Time Recommendation Generation\n",
        "\n",
        "### Objective\n",
        "Demonstrate how the trained model generates personalized recommendations in a production environment. This involves:\n",
        "1. **User Context Retrieval**: Fetching historical interactions from app analytics\n",
        "2. **Model Loading**: Loading the pre-trained LightGBM model and metadata\n",
        "3. **Feature Engineering**: Building user profile features on-the-fly\n",
        "4. **Recipe Scoring**: Generating relevance scores for all recipes\n",
        "5. **Ranking & Selection**: Returning top-N recommendations\n",
        "\n",
        "### Production Workflow\n",
        "The `RecipeScorer` class orchestrates this entire pipeline, loading the saved model artifacts from training and applying them to score recipes for any user in real-time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 12:36:02,978 - recipe_recommender.etl.fetch_user_interactions - INFO - Initialized UserInteractionFetcher\n",
            "2025-09-30 12:36:02,980 - recipe_recommender.etl.fetch_user_interactions - INFO -    Events file: /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/recipe_recommender/output/combined_events.csv\n",
            "2025-09-30 12:36:02,980 - recipe_recommender.etl.fetch_user_interactions - INFO -    Tracking 8 event types\n",
            "2025-09-30 12:36:02,981 - recipe_recommender.etl.fetch_user_interactions - INFO - Fetching interactions for user: afcacbe1-eaba-415f-b03e-14ed682af65e\n",
            "2025-09-30 12:36:02,981 - recipe_recommender.etl.fetch_user_interactions - INFO - Reading events file in chunks\n",
            "2025-09-30 12:36:03,081 - recipe_recommender.etl.fetch_user_interactions - INFO -    Processed 50,000 rows, found 0 matches...\n",
            "2025-09-30 12:36:03,126 - recipe_recommender.etl.fetch_user_interactions - INFO - Found 74 recipe interactions for user afcacbe1-eaba-415f-b03e-14ed682af65e\n",
            "2025-09-30 12:36:03,127 - recipe_recommender.etl.fetch_user_interactions - INFO -    Processed 63,662 total events\n",
            "2025-09-30 12:36:03,129 - recipe_recommender.etl.fetch_user_interactions - INFO -    Time range: 2025-06-03 to 2025-08-24\n",
            "2025-09-30 12:36:03,130 - recipe_recommender.etl.fetch_user_interactions - INFO -    Event breakdown: {'Recipe Added To Collections': 10, 'Recipe Removed From Collections': 2, 'Recipe Link Clicked': 31, 'Recipe Cook Started': 9, 'Recipe Cooked': 8, 'Recipe Search Queried': 14}\n",
            "2025-09-30 12:36:03,131 - recipe_recommender.inference.recipe_scorer - INFO - Initializing Recipe Scorer\n",
            "2025-09-30 12:36:03,132 - recipe_recommender.inference.recipe_scorer - INFO - Loading trained model components...\n",
            "2025-09-30 12:36:03,137 - recipe_recommender.inference.recipe_scorer - INFO - Loaded LIGHTGBM model\n",
            "2025-09-30 12:36:03,138 - recipe_recommender.inference.recipe_scorer - INFO - Loaded model metadata with 28 features\n",
            "2025-09-30 12:36:03,152 - recipe_recommender.inference.recipe_scorer - INFO - Loaded raw recipe features from enhanced_recipe_features_from_db.csv\n",
            "2025-09-30 12:36:03,155 - recipe_recommender.inference.recipe_scorer - INFO - Loaded 1967 recipes for scoring\n",
            "2025-09-30 12:36:03,158 - recipe_recommender.inference.recipe_scorer - INFO - Loaded 21439 recipe-ingredient relationships\n",
            "2025-09-30 12:36:03,159 - recipe_recommender.inference.recipe_scorer - INFO - Scoring 1967 recipes for user\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating recommendations for user: afcacbe1-eaba-415f-b03e-14ed682af65e\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 12:36:09,752 - recipe_recommender.inference.recipe_scorer - INFO - Generated scores for 1967 recipes\n",
            "2025-09-30 12:36:09,752 - recipe_recommender.inference.recipe_scorer - INFO -    Score range: -2.2355 - 2.3711\n",
            "2025-09-30 12:36:09,753 - recipe_recommender.inference.recipe_scorer - INFO -    No threshold; selecting by top-N\n",
            "2025-09-30 12:36:09,753 - recipe_recommender.inference.recipe_scorer - INFO -    Returning top 100 recommendations\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 100 personalized recommendations:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recipe_id</th>\n",
              "      <th>recipe_name</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1915</td>\n",
              "      <td>Chicken Katsu</td>\n",
              "      <td>2.371124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>Apple Cinnamon French Toast</td>\n",
              "      <td>2.371124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>275</td>\n",
              "      <td>Chocolate Self Saucing Pudding</td>\n",
              "      <td>2.371124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1099</td>\n",
              "      <td>Tiramisu</td>\n",
              "      <td>2.371124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1333</td>\n",
              "      <td>Cauliflower Hash Browns</td>\n",
              "      <td>2.028807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1276</td>\n",
              "      <td>Snickerdoodle Bread</td>\n",
              "      <td>-2.235481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1277</td>\n",
              "      <td>Paleo Pumpkin Bread</td>\n",
              "      <td>-2.235481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1278</td>\n",
              "      <td>Pumpkin Granola</td>\n",
              "      <td>-2.235481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1279</td>\n",
              "      <td>Healthy Blueberry Muffins</td>\n",
              "      <td>-2.235481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1280</td>\n",
              "      <td>Sugar Cookie Overnight Protein Oatmeal</td>\n",
              "      <td>-2.235481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   recipe_id                             recipe_name     score\n",
              "0       1915                           Chicken Katsu  2.371124\n",
              "1          7             Apple Cinnamon French Toast  2.371124\n",
              "2        275          Chocolate Self Saucing Pudding  2.371124\n",
              "3       1099                                Tiramisu  2.371124\n",
              "4       1333                 Cauliflower Hash Browns  2.028807\n",
              "..       ...                                     ...       ...\n",
              "95      1276                     Snickerdoodle Bread -2.235481\n",
              "96      1277                     Paleo Pumpkin Bread -2.235481\n",
              "97      1278                         Pumpkin Granola -2.235481\n",
              "98      1279               Healthy Blueberry Muffins -2.235481\n",
              "99      1280  Sugar Cookie Overnight Protein Oatmeal -2.235481\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 1: Initialize the user interaction fetcher\n",
        "# This component reads user behavior data from our app analytics\n",
        "fetcher = UserInteractionFetcher(config)\n",
        "\n",
        "# Step 2: Select a test user with interaction history\n",
        "# In production, this would be the current user's ID from the API request\n",
        "sample_user_id = 'afcacbe1-eaba-415f-b03e-14ed682af65e'\n",
        "\n",
        "# Alternative: Auto-discover an active user from the event data\n",
        "# This code demonstrates how to find users with substantial interaction history\n",
        "\n",
        "# import pandas as pd\n",
        "# try:\n",
        "#     events_path = config.output_dir / \"combined_events.csv\"\n",
        "#     if events_path.exists():\n",
        "#         df_head = pd.read_csv(events_path, nrows=10000)  # Sample for efficiency\n",
        "#         # Find users with most recipe interactions\n",
        "#         candidates = (\n",
        "#             df_head[df_head[\"event\"].isin(fetcher.recipe_events)][\"distinct_id\"]\n",
        "#             .value_counts().head(10)\n",
        "#         )\n",
        "#         if len(candidates) > 0:\n",
        "#             sample_user_id = candidates.index[0]\n",
        "#             print(f\"Auto-selected user with {candidates.iloc[0]} interactions\")\n",
        "# except Exception as e:\n",
        "#     print(\"Could not auto-select user:\", e)\n",
        "\n",
        "\n",
        "print(\"Generating recommendations for user:\", sample_user_id)\n",
        "\n",
        "# Step 3: Retrieve user's interaction history\n",
        "# This includes all recipe-related events: views, favorites, cooking attempts, etc.\n",
        "interactions = fetcher.fetch_user_interactions(sample_user_id)\n",
        "\n",
        "# Step 4: Initialize the recipe scorer and load the trained model\n",
        "# This loads the LightGBM booster, feature metadata, and recipe catalog\n",
        "scorer = RecipeScorer(config)\n",
        "\n",
        "# Step 5: Generate personalized recommendations\n",
        "# The scorer builds user features, scores all recipes, and returns top-N ranked results\n",
        "result = scorer.get_user_recipe_recommendations(\n",
        "    user_id=sample_user_id,\n",
        "    interaction_history=interactions, \n",
        "    n_recommendations=100\n",
        ")\n",
        "\n",
        "# Step 6: Display the recommendations\n",
        "import pandas as pd\n",
        "recommendations = result.get(\"recommendations\", [])\n",
        "recs_df = pd.DataFrame(recommendations)\n",
        "\n",
        "if recs_df.empty:\n",
        "    print(\"No recommendations generated. Check user interactions and model artifacts.\")\n",
        "else:\n",
        "    print(f\"Generated {len(recommendations)} personalized recommendations:\")\n",
        "    display(recs_df[[\"recipe_id\", \"recipe_name\", \"score\"]].head(100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Production Inference Pipeline Validation ===\n",
            "\n",
            "1. Validating Model Artifacts...\n",
            "   ✓ Trained model file found\n",
            "   ✓ Model metadata file found\n",
            "\n",
            "2. Validating Recipe Database...\n",
            "   ✓ Recipe features database found\n",
            "\n",
            "3. Validating Recommendation Output...\n",
            "   ✓ Generated 100 recommendations\n",
            "   ✓ Score range: -2.235481 to 2.371124 (variance: 4.606605)\n",
            "\n",
            "==================================================\n",
            "✅ VALIDATION PASSED\n",
            "System Status: Ready for Production\n",
            "\n",
            "Example Output:\n",
            "Top Recommendation: 'Chicken Katsu' (score: 2.371124)\n"
          ]
        }
      ],
      "source": [
        "# System Validation and Quality Checks\n",
        "print(\"=== Production Inference Pipeline Validation ===\\n\")\n",
        "\n",
        "validation_errors = []\n",
        "validation_warnings = []\n",
        "\n",
        "# Check 1: Model Artifacts Integrity\n",
        "print(\"1. Validating Model Artifacts...\")\n",
        "model_file = config.model_dir / \"hybrid_lightgbm_model.txt\"\n",
        "metadata_file = config.model_dir / \"hybrid_lightgbm_metadata.json\"\n",
        "\n",
        "if not model_file.exists():\n",
        "    validation_errors.append(f\"Critical: Missing trained model file at {model_file}\")\n",
        "else:\n",
        "    print(\"   ✓ Trained model file found\")\n",
        "\n",
        "if not metadata_file.exists():\n",
        "    validation_errors.append(f\"Critical: Missing model metadata file at {metadata_file}\")\n",
        "else:\n",
        "    print(\"   ✓ Model metadata file found\")\n",
        "\n",
        "# Check 2: Recipe Database Integrity  \n",
        "print(\"\\n2. Validating Recipe Database...\")\n",
        "recipe_features_file = config.output_dir / \"enhanced_recipe_features_from_db.csv\"\n",
        "if not recipe_features_file.exists():\n",
        "    validation_errors.append(f\"Critical: Missing recipe features file at {recipe_features_file}\")\n",
        "else:\n",
        "    print(\"   ✓ Recipe features database found\")\n",
        "\n",
        "# Check 3: Recommendation Quality\n",
        "print(\"\\n3. Validating Recommendation Output...\")\n",
        "recommendations = result.get(\"recommendations\", [])\n",
        "\n",
        "if len(recommendations) == 0:\n",
        "    validation_errors.append(\"Critical: No recommendations generated\")\n",
        "elif len(recommendations) < 5:\n",
        "    validation_warnings.append(f\"Warning: Only {len(recommendations)} recommendations generated (expected 10)\")\n",
        "else:\n",
        "    print(f\"   ✓ Generated {len(recommendations)} recommendations\")\n",
        "\n",
        "# Check 4: Score Distribution Analysis\n",
        "if recommendations:\n",
        "    scores = [rec.get('score', 0) for rec in recommendations]\n",
        "    score_range = max(scores) - min(scores)\n",
        "    \n",
        "    if score_range < 0.001:\n",
        "        validation_warnings.append(\"Warning: Very low score variance - model may not be discriminating\")\n",
        "    else:\n",
        "        print(f\"   ✓ Score range: {min(scores):.6f} to {max(scores):.6f} (variance: {score_range:.6f})\")\n",
        "\n",
        "# Final Validation Report\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "if validation_errors:\n",
        "    print(\"❌ VALIDATION FAILED\")\n",
        "    print(\"Critical Issues:\")\n",
        "    for error in validation_errors:\n",
        "        print(f\"   - {error}\")\n",
        "elif validation_warnings:\n",
        "    print(\"⚠️  VALIDATION PASSED WITH WARNINGS\")\n",
        "    print(\"Warnings:\")\n",
        "    for warning in validation_warnings:\n",
        "        print(f\"   - {warning}\")\n",
        "else:\n",
        "    print(\"✅ VALIDATION PASSED\")\n",
        "    print(\"System Status: Ready for Production\")\n",
        "    \n",
        "    # Display top recommendation as success example\n",
        "    if recommendations:\n",
        "        top_rec = recommendations[0]\n",
        "        print(f\"\\nExample Output:\")\n",
        "        print(f\"Top Recommendation: '{top_rec.get('recipe_name', 'Unknown')}' (score: {top_rec.get('score', 0):.6f})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
