{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PantryPalML: A2 Cloud Demo (Colab/Binder)\n",
        "\n",
        "This notebook runs the full pipeline in a cloud runtime for the A2 submission:\n",
        "\n",
        "- Environment setup (pip install, repo clone if needed)\n",
        "- Load small sample CSVs from the repo (no external DB)\n",
        "- Train LightGBM model (fast config)\n",
        "- Evaluate on held-out split\n",
        "- Demo inference: get top-N recommendations for a sample user\n",
        "\n",
        "Run: Runtime â†’ Run all.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Env Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment ready. Project root: /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/notebooks\n"
          ]
        }
      ],
      "source": [
        "# If running on Colab, install dependencies and clone repo without IPython magics\n",
        "import sys, subprocess, os, pathlib\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "repo_root = pathlib.Path.cwd()\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Install required packages\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                        \"lightgbm\", \"pandas\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"seaborn\"],\n",
        "                       check=False)\n",
        "    except Exception as e:\n",
        "        print(f\"pip install warning: {e}\")\n",
        "\n",
        "    # Clone the repo if not present\n",
        "    if not (repo_root / \"recipe_recommender\").exists():\n",
        "        subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/marcel-qayoom-taylor/PantryPalML.git\"], check=True)\n",
        "        os.chdir(\"PantryPalML\")\n",
        "        repo_root = pathlib.Path.cwd()\n",
        "\n",
        "print(f\"Environment ready. Project root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Source Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root set to: /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML\n",
            "Checking for dataframes\n",
            "/Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/recipe_recommender/output/hybrid_train_data.csv\n",
            "(12438, 40) (4146, 40) (4146, 40)\n"
          ]
        }
      ],
      "source": [
        "# Fast config: paths to sample CSVs included in repo\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "# If we're in the notebooks directory, go up one level to find the project root\n",
        "if ROOT.name == \"notebooks\" and (ROOT.parent / \"recipe_recommender\").exists():\n",
        "    PROJECT_ROOT = ROOT.parent\n",
        "elif (ROOT / \"notebooks\").exists() and (ROOT / \"recipe_recommender\").exists():\n",
        "    PROJECT_ROOT = ROOT\n",
        "elif (ROOT / \"PantryPalML\").exists():\n",
        "    PROJECT_ROOT = ROOT / \"PantryPalML\"\n",
        "else:\n",
        "    PROJECT_ROOT = ROOT\n",
        "\n",
        "print(f\"Project root set to: {PROJECT_ROOT}\")\n",
        "\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"recipe_recommender\" / \"output\"\n",
        "\n",
        "# Load small sample CSVs (fallback to generated minimal frames if missing)\n",
        "train_path = OUTPUT_DIR / \"hybrid_train_data.csv\"\n",
        "val_path = OUTPUT_DIR / \"hybrid_val_data.csv\"\n",
        "test_path = OUTPUT_DIR / \"hybrid_test_data.csv\"\n",
        "print(\"Checking for dataframes\")\n",
        "print(train_path)\n",
        "\n",
        "if all(p.exists() for p in [train_path, val_path, test_path]):\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    val_df = pd.read_csv(val_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "else:\n",
        "    # Minimal fallback for demo\n",
        "    import numpy as np\n",
        "    print(\"Generating minimal fallback dataframes\")\n",
        "    rng = np.random.default_rng(42)\n",
        "    cols = [\"user_id\", \"recipe_id\", \"label\", \"avg_rating\", \"ingredient_count\", \"complexity_score\"]\n",
        "    train_df = pd.DataFrame({\n",
        "        \"user_id\": [f\"u{i}\" for i in range(100)],\n",
        "        \"recipe_id\": [f\"r{i%20}\" for i in range(100)],\n",
        "        \"label\": rng.integers(0, 2, size=100),\n",
        "        \"avg_rating\": rng.uniform(2.0, 5.0, size=100),\n",
        "        \"ingredient_count\": rng.integers(3, 15, size=100),\n",
        "        \"complexity_score\": rng.uniform(1.0, 10.0, size=100),\n",
        "    })[cols]\n",
        "    val_df = train_df.sample(frac=0.2, random_state=1).reset_index(drop=True)\n",
        "    test_df = train_df.sample(frac=0.2, random_state=2).reset_index(drop=True)\n",
        "\n",
        "print(train_df.shape, val_df.shape, test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution:\n",
            "Positive (label=1): 2488 (20.00%)\n",
            "Negative (label=0): 9950 (80.00%)\n",
            "\n",
            "Using 20 numeric features for training:\n",
            "['unique_recipes', 'activity_days', 'interactions_per_day', 'engagement_score', 'prep_time', 'cook_time', 'total_time', 'servings', 'author_id', 'instruction'] ...\n",
            "\n",
            "Prediction stats: min=0.0297, mean=0.2007, max=0.8890\n",
            "\n",
            "Results with fixed threshold = 0.0475 (from ROC curve / Youden's J on validation set):\n",
            "{'AUC': 0.9994948710684768, 'Precision': 0.8962162162162162, 'Recall': 1.0, 'F1': 0.9452679589509693}\n"
          ]
        }
      ],
      "source": [
        "# Train a small LightGBM model (fast settings)\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Check class balance first\n",
        "print(f\"Class distribution:\")\n",
        "print(f\"Positive (label=1): {train_df['label'].sum()} ({train_df['label'].mean():.2%})\")\n",
        "print(f\"Negative (label=0): {(train_df['label'] == 0).sum()} ({(train_df['label'] == 0).mean():.2%})\")\n",
        "\n",
        "# Select numeric features and remove likely leaky features\n",
        "exclude_cols = [\"user_id\", \"recipe_id\", \"label\", \"datetime\"]\n",
        "# Remove likely leaky features that might directly relate to the target\n",
        "leaky_features = [\"rating\", \"total_rating\", \"avg_rating\", \"rating_std\", \"total_interactions\"]\n",
        "exclude_cols.extend(leaky_features)\n",
        "\n",
        "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "feature_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
        "\n",
        "print(f\"\\nUsing {len(feature_cols)} numeric features for training:\")\n",
        "print(feature_cols[:10], \"...\" if len(feature_cols) > 10 else \"\")\n",
        "\n",
        "X_train, y_train = train_df[feature_cols], train_df[\"label\"]\n",
        "X_val, y_val = val_df[feature_cols], val_df[\"label\"]\n",
        "\n",
        "# Check if we have any features left\n",
        "if len(feature_cols) == 0:\n",
        "    print(\"WARNING: No features available after filtering!\")\n",
        "    # Use minimal features for demo\n",
        "    feature_cols = [\"unique_recipes\", \"activity_days\", \"prep_time\"][:3]  # Use first available\n",
        "    X_train, y_train = train_df[feature_cols], train_df[\"label\"]\n",
        "    X_val, y_val = val_df[feature_cols], val_df[\"label\"]\n",
        "\n",
        "train_set = lgb.Dataset(X_train, label=y_train)\n",
        "val_set = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": [\"auc\"],\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"num_leaves\": 31,\n",
        "    \"min_data_in_leaf\": 10,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"verbosity\": -1,\n",
        "}\n",
        "\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    train_set,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=[val_set],\n",
        "    valid_names=[\"val\"],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)],\n",
        ")\n",
        "\n",
        "# Get predictions\n",
        "val_pred = model.predict(X_val)\n",
        "print(f\"\\nPrediction stats: min={val_pred.min():.4f}, mean={val_pred.mean():.4f}, max={val_pred.max():.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Fixed production threshold chosen via ROC curve (Youden's J) on validation set\n",
        "MODEL_THRESHOLD = 0.0475\n",
        "val_label_fixed = (val_pred >= MODEL_THRESHOLD).astype(int)\n",
        "\n",
        "print(f\"\\nResults with fixed threshold = {MODEL_THRESHOLD:.4f} (from ROC curve / Youden's J on validation set):\")\n",
        "print({\n",
        "    \"AUC\": float(roc_auc_score(y_val, val_pred)),\n",
        "    \"Precision\": float(precision_score(y_val, val_label_fixed, zero_division=0)),\n",
        "    \"Recall\": float(recall_score(y_val, val_label_fixed, zero_division=0)),\n",
        "    \"F1\": float(f1_score(y_val, val_label_fixed, zero_division=0)),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perform Inference on a Sample User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recipe_id</th>\n",
              "      <th>score</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1714</th>\n",
              "      <td>B90D1B38-A110-4488-9976-673EB98BB878</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3840</th>\n",
              "      <td>28BA7C9C-F2D9-446A-B5EF-CDA07AC97F7D</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3564</th>\n",
              "      <td>3D52259D-B5A1-4805-A464-6D45A478BCEC</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1193</th>\n",
              "      <td>22BA225A-FC6B-46E4-895F-C95FC01074BF</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3836</th>\n",
              "      <td>EA49A478-2600-424D-8C77-40D1B3C6F263</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3838</th>\n",
              "      <td>4A604C96-D440-4F0D-883E-6735E5DB0F18</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2813</th>\n",
              "      <td>D9746C0A-8C57-4327-8420-743ABD422E8C</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>5FA20A04-7FFF-4F62-8038-E4B5487A7A15</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3560</th>\n",
              "      <td>0C3BC142-6A8E-4EBD-944D-D22DADF1D4F5</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>F93C37F8-02D2-4A8D-B6F0-5BDF0CEC1C2E</td>\n",
              "      <td>0.889048</td>\n",
              "      <td>demo_user</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 recipe_id     score    user_id\n",
              "1714  B90D1B38-A110-4488-9976-673EB98BB878  0.889048  demo_user\n",
              "3840  28BA7C9C-F2D9-446A-B5EF-CDA07AC97F7D  0.889048  demo_user\n",
              "3564  3D52259D-B5A1-4805-A464-6D45A478BCEC  0.889048  demo_user\n",
              "1193  22BA225A-FC6B-46E4-895F-C95FC01074BF  0.889048  demo_user\n",
              "3836  EA49A478-2600-424D-8C77-40D1B3C6F263  0.889048  demo_user\n",
              "3838  4A604C96-D440-4F0D-883E-6735E5DB0F18  0.889048  demo_user\n",
              "2813  D9746C0A-8C57-4327-8420-743ABD422E8C  0.889048  demo_user\n",
              "520   5FA20A04-7FFF-4F62-8038-E4B5487A7A15  0.889048  demo_user\n",
              "3560  0C3BC142-6A8E-4EBD-944D-D22DADF1D4F5  0.889048  demo_user\n",
              "525   F93C37F8-02D2-4A8D-B6F0-5BDF0CEC1C2E  0.889048  demo_user"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Demo inference: score and rank recipes for a sample user\n",
        "def recommend_for_user(user_id: str, candidate_df: pd.DataFrame, top_n: int = 5):\n",
        "    # In a full system, we'd build personalized features; here we score with trained model\n",
        "    X = candidate_df[feature_cols]\n",
        "    scores = model.predict(X)\n",
        "    out = candidate_df[[\"recipe_id\"]].copy()\n",
        "    out[\"score\"] = scores\n",
        "    out[\"user_id\"] = user_id\n",
        "    return out.sort_values(\"score\", ascending=False).head(top_n)\n",
        "\n",
        "sample_user = \"demo_user\"\n",
        "# Use test_df as candidates for demo\n",
        "recs = recommend_for_user(sample_user, test_df, top_n=10)\n",
        "recs.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SMOKE TEST: PASS\n",
            "Train/Val/Test sizes: 12438, 4146, 4146\n",
            "Features used: 20\n"
          ]
        }
      ],
      "source": [
        "# Smoke test: end-to-end checks\n",
        "import numpy as np\n",
        "\n",
        "def smoke_test():\n",
        "    errors = []\n",
        "\n",
        "    # Basic dataset checks\n",
        "    try:\n",
        "        for name, df in [(\"train_df\", train_df), (\"val_df\", val_df), (\"test_df\", test_df)]:\n",
        "            if df is None or len(df) == 0:\n",
        "                errors.append(f\"{name} is empty or not loaded\")\n",
        "    except NameError as e:\n",
        "        errors.append(f\"Dataframes not defined: {e}\")\n",
        "\n",
        "    # Feature column checks\n",
        "    try:\n",
        "        missing = [c for c in feature_cols if c not in train_df.columns]\n",
        "        if missing:\n",
        "            errors.append(f\"Missing feature columns in train_df: {missing[:5]} ...\")\n",
        "\n",
        "        non_numeric = [c for c in feature_cols if not np.issubdtype(train_df[c].dtype, np.number)]\n",
        "        if non_numeric:\n",
        "            errors.append(f\"Non-numeric features found: {non_numeric[:5]} ...\")\n",
        "    except Exception as e:\n",
        "        errors.append(f\"Feature column validation failed: {e}\")\n",
        "\n",
        "    # Model prediction checks\n",
        "    try:\n",
        "        _val_pred = model.predict(val_df[feature_cols])\n",
        "        if len(_val_pred) != len(val_df):\n",
        "            errors.append(\"Prediction length mismatch with validation data\")\n",
        "        if not np.all(np.isfinite(_val_pred)):\n",
        "            errors.append(\"Non-finite values in predictions\")\n",
        "    except Exception as e:\n",
        "        errors.append(f\"Model prediction failed: {e}\")\n",
        "\n",
        "    # Recommendation output checks\n",
        "    try:\n",
        "        _recs = recommend_for_user(\"smoke_user\", test_df.head(20).copy(), top_n=5)\n",
        "        required_cols = {\"user_id\", \"recipe_id\", \"score\"}\n",
        "        if not required_cols.issubset(set(_recs.columns)):\n",
        "            errors.append(f\"Recommendation output missing columns: {required_cols - set(_recs.columns)}\")\n",
        "        if len(_recs) == 0:\n",
        "            errors.append(\"No recommendations returned\")\n",
        "    except Exception as e:\n",
        "        errors.append(f\"Recommendation function failed: {e}\")\n",
        "\n",
        "    if errors:\n",
        "        print(\"SMOKE TEST: FAIL\")\n",
        "        for err in errors:\n",
        "            print(\" -\", err)\n",
        "        raise AssertionError(\"Smoke test failed\")\n",
        "    else:\n",
        "        print(\"SMOKE TEST: PASS\")\n",
        "        print(f\"Train/Val/Test sizes: {len(train_df)}, {len(val_df)}, {len(test_df)}\")\n",
        "        print(f\"Features used: {len(feature_cols)}\")\n",
        "\n",
        "smoke_test()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
