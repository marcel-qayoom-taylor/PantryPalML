{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PantryPalML: A2 Cloud Demo (Colab/Binder)\n",
        "\n",
        "This notebook runs the full pipeline in a cloud runtime for the A2 submission:\n",
        "\n",
        "- Environment setup (pip install, repo clone if needed)\n",
        "- Load small sample CSVs from the repo (no external DB)\n",
        "- Train LightGBM model (fast config)\n",
        "- Evaluate on held-out split\n",
        "- Demo inference: get top-N recommendations for a sample user\n",
        "\n",
        "Run: Runtime â†’ Run all.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running on Colab, install dependencies and clone repo without IPython magics\n",
        "import sys, subprocess, os, pathlib\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "repo_root = pathlib.Path.cwd()\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Install required packages\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                        \"lightgbm\", \"pandas\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"seaborn\"],\n",
        "                       check=False)\n",
        "    except Exception as e:\n",
        "        print(f\"pip install warning: {e}\")\n",
        "\n",
        "    # Clone the repo if not present\n",
        "    if not (repo_root / \"recipe_recommender\").exists():\n",
        "        subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/marcel-qayoom-taylor/PantryPalML.git\"], check=True)\n",
        "        os.chdir(\"PantryPalML\")\n",
        "        repo_root = pathlib.Path.cwd()\n",
        "\n",
        "print(f\"Environment ready. Project root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fast config: paths to sample CSVs included in repo\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "if (ROOT / \"notebooks\").exists() and (ROOT / \"recipe_recommender\").exists():\n",
        "    PROJECT_ROOT = ROOT\n",
        "elif (ROOT / \"PantryPalML\").exists():\n",
        "    PROJECT_ROOT = ROOT / \"PantryPalML\"\n",
        "else:\n",
        "    PROJECT_ROOT = ROOT\n",
        "\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"recipe_recommender\" / \"output\"\n",
        "\n",
        "# Load small sample CSVs (fallback to generated minimal frames if missing)\n",
        "train_path = OUTPUT_DIR / \"hybrid_train_data.csv\"\n",
        "val_path = OUTPUT_DIR / \"hybrid_val_data.csv\"\n",
        "test_path = OUTPUT_DIR / \"hybrid_test_data.csv\"\n",
        "\n",
        "if all(p.exists() for p in [train_path, val_path, test_path]):\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    val_df = pd.read_csv(val_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "else:\n",
        "    # Minimal fallback for demo\n",
        "    import numpy as np\n",
        "    rng = np.random.default_rng(42)\n",
        "    cols = [\"user_id\", \"recipe_id\", \"label\", \"avg_rating\", \"ingredient_count\", \"complexity_score\"]\n",
        "    train_df = pd.DataFrame({\n",
        "        \"user_id\": [f\"u{i}\" for i in range(100)],\n",
        "        \"recipe_id\": [f\"r{i%20}\" for i in range(100)],\n",
        "        \"label\": rng.integers(0, 2, size=100),\n",
        "        \"avg_rating\": rng.uniform(2.0, 5.0, size=100),\n",
        "        \"ingredient_count\": rng.integers(3, 15, size=100),\n",
        "        \"complexity_score\": rng.uniform(1.0, 10.0, size=100),\n",
        "    })[cols]\n",
        "    val_df = train_df.sample(frac=0.2, random_state=1).reset_index(drop=True)\n",
        "    test_df = train_df.sample(frac=0.2, random_state=2).reset_index(drop=True)\n",
        "\n",
        "print(train_df.shape, val_df.shape, test_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a small LightGBM model (fast settings)\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
        "\n",
        "feature_cols = [c for c in train_df.columns if c not in [\"user_id\", \"recipe_id\", \"label\", \"datetime\"]]\n",
        "X_train, y_train = train_df[feature_cols], train_df[\"label\"]\n",
        "X_val, y_val = val_df[feature_cols], val_df[\"label\"]\n",
        "\n",
        "train_set = lgb.Dataset(X_train, label=y_train)\n",
        "val_set = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"binary\",\n",
        "    \"metric\": [\"auc\"],\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"num_leaves\": 31,\n",
        "    \"min_data_in_leaf\": 10,\n",
        "    \"feature_fraction\": 0.9,\n",
        "    \"bagging_fraction\": 0.9,\n",
        "    \"bagging_freq\": 1,\n",
        "    \"verbosity\": -1,\n",
        "}\n",
        "\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    train_set,\n",
        "    num_boost_round=100,\n",
        "    valid_sets=[val_set],\n",
        "    valid_names=[\"val\"],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)],\n",
        ")\n",
        "\n",
        "val_pred = model.predict(X_val)\n",
        "val_label = (val_pred >= 0.5).astype(int)\n",
        "\n",
        "print({\n",
        "    \"AUC\": float(roc_auc_score(y_val, val_pred)),\n",
        "    \"Precision\": float(precision_score(y_val, val_label, zero_division=0)),\n",
        "    \"Recall\": float(recall_score(y_val, val_label, zero_division=0)),\n",
        "    \"F1\": float(f1_score(y_val, val_label, zero_division=0)),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo inference: score and rank recipes for a sample user\n",
        "import numpy as np\n",
        "\n",
        "def recommend_for_user(user_id: str, candidate_df: pd.DataFrame, top_n: int = 5):\n",
        "    # In a full system, we'd build personalized features; here we score with trained model\n",
        "    X = candidate_df[feature_cols]\n",
        "    scores = model.predict(X)\n",
        "    out = candidate_df[[\"recipe_id\"]].copy()\n",
        "    out[\"score\"] = scores\n",
        "    out[\"user_id\"] = user_id\n",
        "    return out.sort_values(\"score\", ascending=False).head(top_n)\n",
        "\n",
        "sample_user = \"demo_user\"\n",
        "# Use test_df as candidates for demo\n",
        "recs = recommend_for_user(sample_user, test_df, top_n=10)\n",
        "recs.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Smoke test: end-to-end checks\n",
        "import numpy as np\n",
        "\n",
        "def smoke_test():\n",
        "    errors = []\n",
        "\n",
        "    # Basic dataset checks\n",
        "    try:\n",
        "        for name, df in [(\"train_df\", train_df), (\"val_df\", val_df), (\"test_df\", test_df)]:\n",
        "            if df is None or len(df) == 0:\n",
        "                errors.append(f\"{name} is empty or not loaded\")\n",
        "    except NameError as e:\n",
        "        errors.append(f\"Dataframes not defined: {e}\")\n",
        "\n",
        "    # Feature column checks\n",
        "    try:\n",
        "        missing = [c for c in feature_cols if c not in train_df.columns]\n",
        "        if missing:\n",
        "            errors.append(f\"Missing feature columns in train_df: {missing[:5]} ...\")\n",
        "\n",
        "        non_numeric = [c for c in feature_cols if not np.issubdtype(train_df[c].dtype, np.number)]\n",
        "        if non_numeric:\n",
        "            errors.append(f\"Non-numeric features found: {non_numeric[:5]} ...\")\n",
        "    except Exception as e:\n",
        "        errors.append(f\"Feature column validation failed: {e}\")\n",
        "\n",
        "    # Model prediction checks\n",
        "    try:\n",
        "        _val_pred = model.predict(val_df[feature_cols])\n",
        "        if len(_val_pred) != len(val_df):\n",
        "            errors.append(\"Prediction length mismatch with validation data\")\n",
        "        if not np.all(np.isfinite(_val_pred)):\n",
        "            errors.append(\"Non-finite values in predictions\")\n",
        "    except Exception as e:\n",
        "        errors.append(f\"Model prediction failed: {e}\")\n",
        "\n",
        "    # Recommendation output checks\n",
        "    try:\n",
        "        _recs = recommend_for_user(\"smoke_user\", test_df.head(20).copy(), top_n=5)\n",
        "        required_cols = {\"user_id\", \"recipe_id\", \"score\"}\n",
        "        if not required_cols.issubset(set(_recs.columns)):\n",
        "            errors.append(f\"Recommendation output missing columns: {required_cols - set(_recs.columns)}\")\n",
        "        if len(_recs) == 0:\n",
        "            errors.append(\"No recommendations returned\")\n",
        "    except Exception as e:\n",
        "        errors.append(f\"Recommendation function failed: {e}\")\n",
        "\n",
        "    if errors:\n",
        "        print(\"SMOKE TEST: FAIL\")\n",
        "        for err in errors:\n",
        "            print(\" -\", err)\n",
        "        raise AssertionError(\"Smoke test failed\")\n",
        "    else:\n",
        "        print(\"SMOKE TEST: PASS\")\n",
        "        print(f\"Train/Val/Test sizes: {len(train_df)}, {len(val_df)}, {len(test_df)}\")\n",
        "        print(f\"Features used: {len(feature_cols)}\")\n",
        "\n",
        "smoke_test()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
