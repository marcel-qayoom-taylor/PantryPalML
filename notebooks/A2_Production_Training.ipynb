{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PantryPalML: Production Training Notebook\n",
        "\n",
        "This notebook demonstrates how I build and train the production model used by `ProductionRecipeScorer`.\n",
        "\n",
        "It reuses our modules via imports and shows:\n",
        "- Environment setup (Colab-friendly)\n",
        "- Data preparation using `HybridRecommendationDataBuilder`\n",
        "- Model training, evaluation, and saving via `HybridGBMRecommender`\n",
        "- Artifacts produced for inference (model + metadata)\n",
        "- Brief discussion of task, loss, metrics, and practical objective alignment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab/Local environment setup (silent if local)\n",
        "import sys, subprocess, os, pathlib\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "repo_root = pathlib.Path.cwd()\n",
        "\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                        \"lightgbm\", \"pandas\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"seaborn\"],\n",
        "                       check=False)\n",
        "    except Exception as e:\n",
        "        print(f\"pip install warning: {e}\")\n",
        "\n",
        "    if not (repo_root / \"recipe_recommender\").exists():\n",
        "        subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/marcel-qayoom-taylor/PantryPalML.git\"], check=True)\n",
        "        os.chdir(\"PantryPalML\")\n",
        "        repo_root = pathlib.Path.cwd()\n",
        "\n",
        "print(f\"Environment ready. Project root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports from production codebase\n",
        "from recipe_recommender.config import get_ml_config\n",
        "from recipe_recommender.models.hybrid_recommendation_data_builder import HybridRecommendationDataBuilder\n",
        "from recipe_recommender.models.hybrid_gbm_recommender import HybridGBMRecommender\n",
        "\n",
        "# Central config object (paths, hyperparams, event weights)\n",
        "config = get_ml_config()\n",
        "print(\"Config paths:\")\n",
        "print(\" - output_dir:\", config.output_dir)\n",
        "print(\" - input_dir:\", config.input_dir)\n",
        "print(\" - model_dir:\", config.model_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Training Data\n",
        "I create ML-ready datasets from our real event logs + recipe DB extracts using `HybridRecommendationDataBuilder`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build datasets. Orchestrates loading and feature engineering\n",
        "builder = HybridRecommendationDataBuilder(config)  # \n",
        "\n",
        "# Reads recipe input data from database\n",
        "ok_recipes = builder.load_real_recipe_data()\n",
        "# Reads user interaction history from event logs\n",
        "ok_events = builder.extract_user_interactions_from_events()\n",
        "\n",
        "if not (ok_recipes and ok_events):\n",
        "    raise RuntimeError(\"Missing required data files. Ensure recipe and event outputs exist in recipe_recommender/output.\")\n",
        "\n",
        "# Aggregates per-user stats (avg/total rating, activity, device/platform, engagement)\n",
        "user_profiles = builder.create_user_profiles()\n",
        "# Generates positive/negative user–recipe pairs with labels\n",
        "training_pairs = builder.create_user_recipe_pairs()\n",
        "# Final feature matrix + train/val/test CSVs and metadata/feature list\n",
        "train_df, val_df, test_df = builder.prepare_training_data()\n",
        "\n",
        "print(train_df.shape, val_df.shape, test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train, Evaluate, Save Model\n",
        "I train `HybridGBMRecommender`, evaluate on validation data with appropriate metrics, and save artifacts used by inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate\n",
        "recommender = HybridGBMRecommender(config)  # wraps LightGBM with config-driven hyperparams and tracked features\n",
        "\n",
        "# Reads train/val/test CSVs prepared by the data builder\n",
        "recommender.load_training_data()\n",
        "# Ensures recipe-level features are available (used for context/eval)\n",
        "recommender.load_recipe_features()\n",
        "\n",
        "# Fits LightGBM Lambdarank (ranking) with early stopping (NDCG on validation)\n",
        "recommender.train_model()\n",
        "\n",
        "# Reports AUC/Precision/Recall/F1 and per-user NDCG@k ranking metrics\n",
        "recommender.evaluate_model()\n",
        "# LightGBM feature importance by gain (sum loss reduction per feature)\n",
        "importance = recommender.get_feature_importance()\n",
        "print(\"Top 10 features:\\n\", importance.head(10))\n",
        "\n",
        "# Writes booster + metadata (feature columns, config, training stats) to model_dir\n",
        "recommender.save_model()\n",
        "\n",
        "print(\"Artifacts saved in:\", config.model_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes on Learning Task and Objective\n",
        "- Input (train): user–recipe feature matrix with label indicating positive interaction\n",
        "- Output (deploy): score per recipe for a given user\n",
        "- Learning objective: LightGBM Lambdarank (pairwise ranking) optimized for NDCG@k\n",
        "- Evaluation: primary ranking metrics NDCG@k (+ Recall@k); AUC/PR are reference only\n",
        "- Alignment: We optimize directly for ranking quality to match top-N recommendation goals\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Lambdarank (and how it works)\n",
        "\n",
        "- **Why this objective**\n",
        "  - **We care about ranking, not calibrated probabilities**: recommendations are evaluated by order (top‑K), so optimizing NDCG@k aligns the loss with our goal.\n",
        "  - **Direct optimization of a ranking surrogate**: Lambdarank approximates NDCG gains, typically improving NDCG/Recall over binary logloss in recommendation tasks.\n",
        "  - **Handles class imbalance and variable list sizes**: Works well with sparse positives and per‑user candidate sets of different lengths.\n",
        "\n",
        "- **How it works (intuitively)**\n",
        "  - For each user (a \"group\"), the model forms **pairwise preferences** between items and computes gradients (\"lambdas\") proportional to the **change in NDCG** if a pair were swapped.\n",
        "  - LightGBM then **boosts decision trees** to reduce this surrogate loss, directly pushing relevant items upward in the list.\n",
        "  - We pass per‑user group sizes, set `objective = \"lambdarank\"`, `metric = \"ndcg\"`, and choose `ndcg_eval_at = (5, 10, 20)` for validation/early stopping.\n",
        "\n",
        "- **Loss used**\n",
        "  - Pairwise logistic loss on score differences with lambda weights approximating ΔNDCG: `L = log(1 + exp(-(s_i - s_j)))`, weighted by per‑pair lambdas derived from the expected NDCG change.\n",
        "\n",
        "- **Practical effects**\n",
        "  - Training stops when validation NDCG@k stops improving.\n",
        "  - At inference we get scores; **higher score ⇒ higher rank**. No thresholding is required for top‑N recommendations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Smoke Test: Saved Artifacts\n",
        "Verify that the trained model and metadata were written to `config.model_dir`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_file = config.model_dir / \"hybrid_lightgbm_model.txt\"\n",
        "meta_file = config.model_dir / \"hybrid_lightgbm_metadata.json\"\n",
        "\n",
        "print(\"Model exists:\", model_file.exists(), model_file)\n",
        "print(\"Metadata exists:\", meta_file.exists(), meta_file)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
