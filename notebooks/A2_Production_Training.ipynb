{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 2: Production Model Training for Recipe Recommendation System\n",
        "\n",
        "## Project Overview\n",
        "This notebook demonstrates the development and training of a machine learning model for a recipe recommendation system for my mobile app PantryPal. \n",
        "PantryPal is a real-world cooking app where users can input the ingredients that they have and receive recipe suggestions. In addition to ingredient-count based recommendations,\n",
        "I wanted to incorporate a general recommendation system that tries to rank, out of all 2000 of our recipes, which they would most engage with.\n",
        "\n",
        "As the owner of this recipe app, I have collected real user interaction data (views, favorites, cooking attempts) and built a personalized recommendation system to improve user engagement and help users discover recipes they'll love.\n",
        "\n",
        "## Business Problem\n",
        "PantryPal serves hundreds of users who interact with recipes in various ways. The challenge is to predict which recipes a user is most likely to engage with based on their historical behavior and recipe characteristics. This is a classic collaborative filtering problem with content-based features.\n",
        "\n",
        "## Outline\n",
        "This notebook demonstrates the complete ML pipeline:\n",
        "- Environment setup (Colab-compatible)\n",
        "- Data preparation using `TrainingDataBuilder`\n",
        "- Model training, evaluation, and saving via `RecipeRanker` \n",
        "- Model artifacts for production inference\n",
        "- Discussion of learning objectives, loss functions, and evaluation metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment Setup\n",
        "# This cell configures the environment for both local development and Google Colab\n",
        "import sys, subprocess, os, pathlib\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "repo_root = pathlib.Path.cwd()\n",
        "\n",
        "# Install required packages for Colab environments\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                        \"lightgbm\", \"pandas\", \"numpy\", \"scikit-learn\", \"matplotlib\", \"seaborn\"],\n",
        "                       check=False)\n",
        "    except Exception as e:\n",
        "        print(f\"pip install warning: {e}\")\n",
        "\n",
        "    # Clone the PantryPal ML repository if not already present\n",
        "    if not (repo_root / \"recipe_recommender\").exists():\n",
        "        subprocess.run([\"git\", \"clone\", \"-q\", \"https://github.com/marcel-qayoom-taylor/PantryPalML.git\"], check=True)\n",
        "        os.chdir(\"PantryPalML\")\n",
        "        repo_root = pathlib.Path.cwd()\n",
        "\n",
        "print(f\"Environment ready. Project root: {repo_root}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration Management\n",
        "# Import the centralized configuration system for the ML pipeline\n",
        "from recipe_recommender.config import get_ml_config\n",
        "\n",
        "# The MLConfig object contains all hyperparameters, file paths, and model settings\n",
        "# This approach ensures reproducibility and makes hyperparameter tuning systematic\n",
        "config = get_ml_config()\n",
        "\n",
        "print(\"ML Pipeline Configuration:\")\n",
        "print(\" - output_dir:\", config.output_dir)\n",
        "print(\" - input_dir:\", config.input_dir)\n",
        "print(\" - model_dir:\", config.model_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation Phase\n",
        "\n",
        "### Objective\n",
        "Transform raw user interaction events and recipe metadata into a structured ML dataset suitable for training a ranking model. This involves feature engineering, negative sampling, and creating train/validation/test splits.\n",
        "\n",
        "### Data Sources\n",
        "- **User interaction events**: Real app analytics data showing user engagement with recipes \n",
        "- **Recipe database**: Complete recipe metadata including ingredients, cooking times, ratings, etc.\n",
        "- **Recipe-ingredient relationships**: Detailed ingredient lists for content-based filtering\n",
        "\n",
        "The `TrainingDataBuilder` class orchestrates this entire data preparation pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 12:39:54,765 - recipe_recommender.models.training_data_builder - INFO - Created 16788 negative pairs\n",
            "2025-09-30 12:39:54,768 - recipe_recommender.models.training_data_builder - INFO - Total training pairs: 20985\n",
            "2025-09-30 12:39:54,768 - recipe_recommender.models.training_data_builder - INFO -    Positive: 4197 (20.0%)\n",
            "2025-09-30 12:39:54,769 - recipe_recommender.models.training_data_builder - INFO -    Negative: 16788 (80.0%)\n",
            "2025-09-30 12:39:54,770 - recipe_recommender.models.training_data_builder - INFO - Filtering users with insufficient interactions/positives for ranking\n",
            "2025-09-30 12:39:54,774 - recipe_recommender.models.training_data_builder - INFO -    Kept 563 users eligible for ranking; pairs: 20985 -> 18400\n",
            "2025-09-30 12:39:54,774 - recipe_recommender.models.training_data_builder - INFO - Creating comprehensive training features\n",
            "2025-09-30 12:39:54,792 - recipe_recommender.models.training_data_builder - INFO - Adding author affinity features...\n",
            "2025-09-30 12:39:54,802 - recipe_recommender.models.training_data_builder - INFO - Adding recipe re-engagement features...\n",
            "2025-09-30 12:39:54,816 - recipe_recommender.models.training_data_builder - INFO - Adding ingredient similarity features...\n",
            "2025-09-30 12:40:04,756 - recipe_recommender.models.training_data_builder - INFO -    Average ingredient similarity: 0.0000\n",
            "2025-09-30 12:40:04,759 - recipe_recommender.models.training_data_builder - INFO -    Recipes with common ingredients: 0 / 18400\n",
            "2025-09-30 12:40:04,825 - recipe_recommender.models.training_data_builder - INFO - Created training dataset with 18400 samples and 52 features\n",
            "2025-09-30 12:40:04,826 - recipe_recommender.models.training_data_builder - INFO - Creating train/validation/test splits\n",
            "2025-09-30 12:40:04,848 - recipe_recommender.models.training_data_builder - INFO - Data splits created:\n",
            "2025-09-30 12:40:04,849 - recipe_recommender.models.training_data_builder - INFO -    Train: 11040 samples (60.0%)\n",
            "2025-09-30 12:40:04,849 - recipe_recommender.models.training_data_builder - INFO -    Validation: 3680 samples (20.0%)\n",
            "2025-09-30 12:40:04,849 - recipe_recommender.models.training_data_builder - INFO -    Test: 3680 samples (20.0%)\n",
            "2025-09-30 12:40:05,213 - recipe_recommender.models.training_data_builder - INFO - Saved training data:\n",
            "2025-09-30 12:40:05,213 - recipe_recommender.models.training_data_builder - INFO -    - hybrid_train_data.csv (11040 samples)\n",
            "2025-09-30 12:40:05,213 - recipe_recommender.models.training_data_builder - INFO -    - hybrid_val_data.csv (3680 samples)\n",
            "2025-09-30 12:40:05,214 - recipe_recommender.models.training_data_builder - INFO -    - hybrid_test_data.csv (3680 samples)\n",
            "2025-09-30 12:40:05,214 - recipe_recommender.models.training_data_builder - INFO -    - hybrid_feature_columns.txt (29 features)\n",
            "2025-09-30 12:40:05,214 - recipe_recommender.models.training_data_builder - INFO -    - hybrid_training_metadata.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shapes - Train: (11040, 52) Validation: (3680, 52) Test: (3680, 52)\n"
          ]
        }
      ],
      "source": [
        "# Import the training data builder\n",
        "from recipe_recommender.models.training_data_builder import TrainingDataBuilder\n",
        "\n",
        "# Initialize the data builder with our configuration\n",
        "builder = TrainingDataBuilder(config)\n",
        "\n",
        "# Step 1: Load recipe metadata from the production database\n",
        "# This includes recipe details, ingredients, nutritional info, etc.\n",
        "ok_recipes = builder.load_real_recipe_data()\n",
        "\n",
        "# Step 2: Extract user interaction history from event logs\n",
        "# This processes real app analytics to understand user preferences\n",
        "ok_events = builder.extract_user_interactions_from_events()\n",
        "\n",
        "# Validate that all required data sources are available\n",
        "if not (ok_recipes and ok_events):\n",
        "    raise RuntimeError(\"Missing required data files. Ensure recipe and event outputs exist in recipe_recommender/output.\")\n",
        "\n",
        "# Step 3: Create user profile features \n",
        "# Aggregates per-user statistics: average ratings, activity levels, platform preferences\n",
        "user_profiles = builder.create_user_profiles()\n",
        "\n",
        "# Step 4: Generate training pairs with labels\n",
        "# Creates positive (user engaged with recipe) and negative (user likely not interested) pairs\n",
        "training_pairs = builder.create_user_recipe_pairs()\n",
        "\n",
        "# Step 5: Build final feature matrix and data splits\n",
        "# Combines user profiles, recipe features, and interaction patterns into ML-ready format\n",
        "train_df, val_df, test_df = builder.prepare_training_data()\n",
        "\n",
        "print(\"Dataset shapes - Train:\", train_df.shape, \"Validation:\", val_df.shape, \"Test:\", test_df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training and Evaluation\n",
        "\n",
        "### Objective\n",
        "Train a Learning-to-Rank model using LightGBM's Lambdarank objective to optimize for recommendation quality. The model learns to score user-recipe pairs such that recipes the user is more likely to engage with receive higher scores.\n",
        "\n",
        "### Model Architecture\n",
        "- **Algorithm**: LightGBM Gradient Boosting with Lambdarank objective. \n",
        "- **Loss Function**: LambdaRank doesn't use a traditional loss function but instead directly computes gradients aka \"lambdas\" by considering pairwise document comparisons and weighting them by how much swapping their positions would improve the ranking metric (NDCG in our case). \n",
        "- **Task**: Learning-to-Rank for personalized recipe recommendations  \n",
        "- **Optimization Target**: Normalized Discounted Cumulative Gain (NDCG@k)\n",
        "- **Features**: 34 features (22 computed, 12 natural) combining user behavior, recipe content, and compatibility signals\n",
        "\n",
        "The `RecipeRanker` class handles the complete training, evaluation, and persistence workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 12:40:05,327 - recipe_recommender.models.recipe_ranker - INFO - Initialized Recipe Ranker with lightgbm\n",
            "2025-09-30 12:40:05,328 - recipe_recommender.models.recipe_ranker - INFO - Loading training data\n",
            "2025-09-30 12:40:05,438 - recipe_recommender.models.recipe_ranker - INFO - Successfully loaded training data:\n",
            "2025-09-30 12:40:05,438 - recipe_recommender.models.recipe_ranker - INFO -    Train: 11,040 samples\n",
            "2025-09-30 12:40:05,439 - recipe_recommender.models.recipe_ranker - INFO -    Validation: 3,680 samples\n",
            "2025-09-30 12:40:05,439 - recipe_recommender.models.recipe_ranker - INFO -    Test: 3,680 samples\n",
            "2025-09-30 12:40:05,439 - recipe_recommender.models.recipe_ranker - INFO - Loaded 29 feature columns\n",
            "2025-09-30 12:40:05,440 - recipe_recommender.models.recipe_ranker - INFO - Loaded training metadata\n",
            "2025-09-30 12:40:05,451 - recipe_recommender.models.recipe_ranker - INFO - Loaded raw recipe features from enhanced_recipe_features_from_db.csv\n",
            "2025-09-30 12:40:05,452 - recipe_recommender.models.recipe_ranker - INFO - Loaded 1967 recipes for scoring\n",
            "2025-09-30 12:40:05,452 - recipe_recommender.models.recipe_ranker - INFO - Training LIGHTGBM model\n",
            "2025-09-30 12:40:05,452 - recipe_recommender.models.recipe_ranker - INFO - Preparing features for training\n",
            "2025-09-30 12:40:05,453 - recipe_recommender.models.recipe_ranker - INFO - Using 28 numeric features\n",
            "2025-09-30 12:40:05,454 - recipe_recommender.models.recipe_ranker - INFO - Training data shape: (11040, 28)\n",
            "2025-09-30 12:40:05,455 - recipe_recommender.models.recipe_ranker - INFO -    Positive samples: 3,189.0 (28.9%)\n",
            "2025-09-30 12:40:05,672 - recipe_recommender.models.recipe_ranker - INFO - Model training completed\n",
            "2025-09-30 12:40:05,673 - recipe_recommender.models.recipe_ranker - INFO - Evaluating model performance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[11]\ttrain's ndcg@5: 0.99962\ttrain's ndcg@10: 0.999601\ttrain's ndcg@20: 0.999672\tvalidation's ndcg@5: 1\tvalidation's ndcg@10: 1\tvalidation's ndcg@20: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 12:40:05,915 - recipe_recommender.models.recipe_ranker - INFO - Model performance:\n",
            "2025-09-30 12:40:05,916 - recipe_recommender.models.recipe_ranker - INFO -    NDCG@5: 0.6545\n",
            "2025-09-30 12:40:05,916 - recipe_recommender.models.recipe_ranker - INFO -    NDCG@10: 0.6545\n",
            "2025-09-30 12:40:05,916 - recipe_recommender.models.recipe_ranker - INFO -    Recall@5: 0.9555\n",
            "2025-09-30 12:40:05,916 - recipe_recommender.models.recipe_ranker - INFO -    Recall@10: 0.9894\n",
            "2025-09-30 12:40:05,916 - recipe_recommender.models.recipe_ranker - INFO -    Spearman Correlation: 0.9958\n",
            "2025-09-30 12:40:05,919 - recipe_recommender.models.recipe_ranker - INFO - Saving trained model\n",
            "2025-09-30 12:40:05,921 - recipe_recommender.models.recipe_ranker - INFO - Model saved to: hybrid_lightgbm_model.txt\n",
            "2025-09-30 12:40:05,921 - recipe_recommender.models.recipe_ranker - INFO - Metadata saved to: hybrid_lightgbm_metadata.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 Most Important Features:\n",
            "                          feature   importance\n",
            "20  user_recipe_interaction_count  7023.643156\n",
            "21         user_recipe_max_rating  4744.439364\n",
            "22         user_recipe_avg_rating  2948.425036\n",
            "3                      rating_std    47.143476\n",
            "1                      avg_rating    45.242657\n",
            "4                  unique_recipes    24.522861\n",
            "0              total_interactions    21.124030\n",
            "7                engagement_score    14.515322\n",
            "6            interactions_per_day     9.407445\n",
            "2                    total_rating     8.828276\n",
            "Training complete! Model artifacts saved to: /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/recipe_recommender/output/hybrid_models\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import the recipe ranking model\n",
        "from recipe_recommender.models.recipe_ranker import RecipeRanker\n",
        "\n",
        "# Initialize the ranker with our configuration\n",
        "ranker = RecipeRanker(config)\n",
        "\n",
        "# Step 1: Load the prepared training datasets\n",
        "# This loads the train/validation/test splits created by the TrainingDataBuilder\n",
        "ranker.load_training_data()\n",
        "\n",
        "# Step 2: Load recipe feature metadata\n",
        "# Ensures recipe-level features are available for scoring and evaluation\n",
        "ranker.load_recipe_features()\n",
        "\n",
        "# Step 3: Train the LightGBM model\n",
        "# Uses Lambdarank objective to optimize directly for ranking quality (NDCG)\n",
        "# Early stopping prevents overfitting based on validation NDCG performance\n",
        "ranker.train_model()\n",
        "\n",
        "# Step 4: Evaluate model performance\n",
        "# Reports both classification metrics (AUC, Precision, Recall) and ranking metrics (NDCG@k, Recall@k)\n",
        "ranker.evaluate_model()\n",
        "\n",
        "# Step 5: Analyze feature importance\n",
        "# LightGBM provides feature importance scores based on information gain\n",
        "importance = ranker.get_feature_importance()\n",
        "print(\"Top 10 Most Important Features:\")\n",
        "print(importance.head(10))\n",
        "\n",
        "# Step 6: Save model artifacts for production inference\n",
        "# Saves the trained booster, feature metadata, and configuration\n",
        "ranker.save_model()\n",
        "\n",
        "print(\"Training complete! Model artifacts saved to:\", config.model_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Task Analysis\n",
        "\n",
        "### Problem Formulation\n",
        "This is a **Learning-to-Rank** problem rather than traditional binary classification:\n",
        "\n",
        "- **Input**: User-recipe feature vectors with binary engagement labels (1 = user engaged, 0 = no engagement)\n",
        "- **Output**: Relevance scores for ranking recipes per user\n",
        "- **Objective**: Learn a scoring function that ranks recipes users will engage with higher than those they won't\n",
        "\n",
        "### Model Architecture Decisions\n",
        "- **Algorithm Choice**: LightGBM with Lambdarank objective\n",
        "- **Why Ranking**: We care about the order of recommendations, not calibrated probabilities\n",
        "- **Optimization Target**: NDCG@k directly aligns with business goals (top-N recommendation quality)\n",
        "- **Evaluation**: Primary metrics are NDCG@k and Recall@k;\n",
        "\n",
        "### Business Alignment\n",
        "The Lambdarank objective optimizes for the exact metric we care about in production: presenting users with the most relevant recipes at the top of their recommendation list.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lambdarank Algorithm Analysis\n",
        "\n",
        "### Theoretical Foundation\n",
        "\n",
        "**Lambdarank** is a listwise learning-to-rank algorithm that directly optimizes for ranking evaluation metrics like NDCG\n",
        "\n",
        "### Why Lambdarank for Recipe Recommendations?\n",
        "\n",
        "1. **Metric Alignment**: Traditional classification losses (cross-entropy) don't directly optimize for ranking quality. Lambdarank approximates NDCG gradients, ensuring our training objective matches our evaluation criteria.\n",
        "\n",
        "2. **Handles Recommendation Challenges**:\n",
        "   - **Class imbalance**: Most user-recipe pairs are negative (sparse interactions)\n",
        "   - **Variable list lengths**: Different users have different numbers of candidate recipes\n",
        "   - **Position bias**: Top recommendations matter more than bottom ones\n",
        "\n",
        "3. **Pairwise Learning**: For each user group, the algorithm considers pairs of recipes and learns to score the engaging recipe higher than the non-engaging one.\n",
        "\n",
        "### Technical Implementation\n",
        "\n",
        "- **Objective Function**: `objective = \"lambdarank\"` in LightGBM\n",
        "- **Metric**: `metric = \"ndcg\"` with evaluation at ranks 5, 10, and 20\n",
        "- **Loss Function**: Pairwise logistic loss weighted by lambda coefficients:\n",
        "  ```\n",
        "  L = Σ λ_ij * log(1 + exp(-(s_i - s_j)))\n",
        "  ```\n",
        "  where λ_ij represents the change in NDCG if recipes i and j were swapped\n",
        "\n",
        "### Production Implications\n",
        "\n",
        "- **Scoring**: Model outputs continuous scores; higher scores indicate better recommendations\n",
        "- **Ranking**: No threshold needed—simply rank recipes by score for top-N recommendations\n",
        "- **Optimization**: Early stopping based on validation NDCG prevents overfitting to ranking metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Artifact Verification\n",
        "\n",
        "### Objective\n",
        "Verify that all necessary model artifacts have been correctly saved for production deployment. This ensures the training pipeline completed successfully and the model is ready for inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model exists: True /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/recipe_recommender/output/hybrid_models/hybrid_lightgbm_model.txt\n",
            "Metadata exists: True /Users/marcelqayoomtaylor/Documents/GitHub/PantryPalML/recipe_recommender/output/hybrid_models/hybrid_lightgbm_metadata.json\n"
          ]
        }
      ],
      "source": [
        "model_file = config.model_dir / \"hybrid_lightgbm_model.txt\"\n",
        "meta_file = config.model_dir / \"hybrid_lightgbm_metadata.json\"\n",
        "\n",
        "print(\"Model exists:\", model_file.exists(), model_file)\n",
        "print(\"Metadata exists:\", meta_file.exists(), meta_file)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
