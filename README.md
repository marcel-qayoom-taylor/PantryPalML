# PantryPal Recipe Recommendation System

A production-ready hybrid gradient boosted model (GBM) that combines user interaction history with rich recipe content features to provide personalized recipe recommendations.

## ğŸ¯ What This System Does

**Input:** User's recipe interaction history (viewed, cooked, favourited, etc.)  
**Output:** Scored and ranked recipe recommendations based on predicted user preferences  
**Model:** Hybrid LightGBM combining collaborative filtering + content-based features  

### Key Features
- âš¡ **Real-time scoring**: Score 1,967 recipes in ~0.08 seconds
- ğŸ§  **Hybrid approach**: Combines user behavior with rich recipe metadata  
- ğŸ“Š **High accuracy**: 99.92% AUC, 97.55% F1-score
- ğŸ”§ **Production ready**: Clean API for integration
- ğŸš€ **Scalable**: Handles new users, recipes, and retraining

## ğŸ—ï¸ System Architecture

```
ğŸ“± User Events â†’ ğŸ§  Hybrid GBM Model â†’ ğŸ³ Ranked Recipe Recommendations
     â”‚                    â”‚                           â”‚
     â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
     â”‚              â”‚ User Profileâ”‚                   â”‚  
     â”‚              â”‚  Features   â”‚                   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ Recipe      â”‚
                    â”‚ Content     â”‚
                    â”‚ Features    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    ğŸ“Š Supabase Database
                    (1,967 recipes + metadata)
```

### Data Sources
1. **User Interactions**: Recipe events (viewed, cooked, favourited) from analytics
2. **Recipe Database**: Complete PantryPal recipe catalog from Supabase
3. **Recipe Metadata**: Ingredients, tags, timing, authors, descriptions

### Feature Engineering
- **User Features (11)**: Engagement patterns, cooking frequency, preferences
- **Recipe Features (10)**: Complexity, ingredients, timing, categories
- **Interaction Features (3)**: Compatibility scores between user and recipe characteristics

## ğŸš€ Quick Start - Using the Model

### 1. Setup Environment
```bash
# Install dependencies
uv add pandas numpy scikit-learn lightgbm supabase python-dotenv

# Set up Supabase credentials (required)
export SUPABASE_URL=https://your-project-id.supabase.co
export SUPABASE_ANON_KEY=your-anon-key
export SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
```

### 2. Get Recipe Recommendations
```python
from recipe_recommender.inference.production_recipe_scorer import ProductionRecipeScorer

# Initialize the scorer (loads trained model automatically)
scorer = ProductionRecipeScorer()

# User's interaction history
user_interactions = [
    {"recipe_id": "100", "event_type": "Recipe Viewed", "timestamp": 1755665991},
    {"recipe_id": "100", "event_type": "Recipe Cooked", "timestamp": 1755666000},
    {"recipe_id": "1291", "event_type": "Recipe Favourited", "timestamp": 1755666100}
]

# Get personalized recommendations
recommendations = scorer.get_user_recipe_recommendations(
    user_id="user123",
    interaction_history=user_interactions,
    n_recommendations=10
)

# Use the recommendations
for rec in recommendations['recommendations']:
    print(f"{rec['recipe_name']} (Score: {rec['score']:.4f})")
    print(f"  Author: {rec['author_name']}")
    print(f"  Time: {rec['total_time']}min, Servings: {rec['servings']}")
```

### 3. Configuration Management
The system now uses centralized configuration for easy customization:

```python
from recipe_recommender.config import get_ml_config

# Get default configuration
config = get_ml_config()

# Customize training parameters
config.learning_rate = 0.05
config.num_leaves = 50
config.negative_sampling_ratio = 3

# Use custom config
from recipe_recommender.models.hybrid_gbm_recommender import HybridGBMRecommender
recommender = HybridGBMRecommender(config=config)
```

### 4. Integration Example (FastAPI)
```python
from fastapi import FastAPI
from recipe_recommender.inference.production_recipe_scorer import ProductionRecipeScorer

app = FastAPI()
scorer = ProductionRecipeScorer()

@app.post("/recommendations")
async def get_recommendations(user_id: str, interactions: List[Dict]):
    return scorer.get_user_recipe_recommendations(
        user_id=user_id,
        interaction_history=interactions,
        n_recommendations=20
    )
```

## ğŸ“Š Model Performance

- **AUC**: 99.92% (near-perfect discrimination)
- **Precision**: 99.01% (very few false positives)  
- **Recall**: 96.14% (catches most relevant recipes)
- **F1-Score**: 97.55% (excellent overall performance)
- **NDCG@5**: 62.18% (good ranking quality)

**Training Data:**
- 20,730 user-recipe pairs (831 users Ã— 4,117 recipes)
- 22 engineered features combining user behavior + recipe content
- Temporal train/validation/test split

## ğŸ”„ Retraining with New Data

### When to Retrain
- **New user interactions**: Monthly or when interaction volume increases significantly
- **New recipes**: When new recipes are added to the database
- **Performance degradation**: If recommendation quality decreases

### Retraining Process

#### 1. Update Database
```bash
# Ensure new recipe data is in Supabase
# New user interactions should be in your event tracking
```

#### 2. Extract Fresh Data
```python
# Fetch updated recipe data from Supabase
from recipe_recommender.etl.database.fetch_real_recipes import RealRecipeDataFetcher
fetcher = RealRecipeDataFetcher(use_service_role=True)
dataset = fetcher.build_comprehensive_recipe_dataset()
```

#### 3. Rebuild Training Dataset
```python
# Rebuild training data with latest interactions + recipes
from recipe_recommender.models.hybrid_recommendation_data_builder import HybridRecommendationDataBuilder
builder = HybridRecommendationDataBuilder()
train_data, val_data, test_data = builder.prepare_training_data()
```

#### 4. Retrain Model
```python
# Train new model
from recipe_recommender.models.hybrid_gbm_recommender import HybridGBMRecommender
recommender = HybridGBMRecommender(model_type='lightgbm')
recommender.load_training_data()
recommender.load_recipe_features()
recommender.train_model()
recommender.save_model()
```

#### 5. Deploy Updated Model
```python
# The ProductionRecipeScorer will automatically load the new model
scorer = ProductionRecipeScorer()  # Loads latest trained model
```

### Complete Retraining Script
```bash
# Run the complete retraining pipeline
cd /path/to/PantryPalUtils

# 1. Fetch latest recipe data
uv run python recipe_recommender/etl/database/fetch_real_recipes.py

# 2. Rebuild training dataset  
uv run python recipe_recommender/models/hybrid_recommendation_data_builder.py

# 3. Train new model
uv run python recipe_recommender/models/hybrid_gbm_recommender.py

# 4. Test the updated model
uv run python recipe_recommender/inference/production_recipe_scorer.py
```

## ğŸ“ Project Structure

### Essential Files (Production)
```
recipe_recommender/
â”œâ”€â”€ config.py                       # ğŸ†• Centralized configuration management
â”œâ”€â”€ utils/                          # ğŸ†• Common utilities and helpers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ common.py                   # Shared functionality
â”œâ”€â”€ etl/                            # ğŸ†• Consolidated data extraction & transformation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database/                   # Database operations
â”‚   â”‚   â”œâ”€â”€ supabase_config.py      # Database connection setup
â”‚   â”‚   â””â”€â”€ fetch_real_recipes.py   # Extract recipe data from Supabase
â”‚   â””â”€â”€ events/                     # Event processing (formerly transformations)
â”‚       â”œâ”€â”€ event_transformation.py # Process user interaction events
â”‚       â””â”€â”€ helpers.py              # Utility functions
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ hybrid_recommendation_data_builder.py  # Build training dataset
â”‚   â””â”€â”€ hybrid_gbm_recommender.py   # ğŸ”„ Improved train hybrid GBM model
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ production_recipe_scorer.py # ğŸ”„ Enhanced production recommendation API
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ exploratory_data_analysis.py # Data exploration (reference)
â”‚   â””â”€â”€ feature_engineering.py      # Feature engineering (reference)
â””â”€â”€ output/
    â”œâ”€â”€ hybrid_models/              # Trained model files
    â”œâ”€â”€ hybrid_train_data.csv       # Training dataset
    â”œâ”€â”€ enhanced_recipe_features_from_db.csv  # Recipe features
    â””â”€â”€ real_*.csv                  # Raw data from Supabase
```

### ğŸ†• Key Improvements in This Version

**1. Centralized Configuration (`config.py`)**
- No more hardcoded paths throughout the codebase
- Easy to modify training parameters, file paths, and model settings
- Automatic path detection for different environments

**2. Common Utilities (`utils/`)**
- Eliminated code duplication across files
- Consistent error handling and logging
- Safer file operations with proper validation

**3. Enhanced Documentation**
- Beginner-friendly comments explaining ML concepts
- Clear separation of concerns in each class
- Step-by-step workflow documentation

**4. Better Logging**
- Replaced print statements with proper logging
- Consistent logging format across all modules
- Better debugging and monitoring capabilities

**5. Improved Error Handling**
- Graceful handling of missing files and bad data
- Informative error messages for beginners
- Robust validation of inputs and outputs

### Key Output Files
- **`hybrid_models/hybrid_lightgbm_model.txt`**: Trained LightGBM model
- **`enhanced_recipe_features_from_db.csv`**: Complete recipe dataset with features
- **`hybrid_training_metadata.json`**: Model training configuration and stats

## ğŸ”§ Configuration

### Supabase Setup
1. Go to your Supabase project â†’ Settings â†’ API
2. Set environment variables:
```bash
export SUPABASE_URL=https://awscrmohelsluoiekqud.supabase.co
export SUPABASE_ANON_KEY=your-anon-key
export SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
```

### Database Requirements
The system expects these Supabase tables:
- **`recipe`**: Recipe metadata (names, timing, authors, tags)
- **`ingredient`**: Ingredient catalog with categories
- **`ingredients_of_recipe`**: Recipe-ingredient relationships

## ğŸ’¡ Understanding the Model

### How It Works
1. **User Profiling**: Analyzes interaction patterns to understand preferences
2. **Recipe Content**: Leverages rich recipe metadata (ingredients, complexity, etc.)
3. **Compatibility Scoring**: Matches user preferences with recipe characteristics
4. **Ranking**: Orders recipes by predicted preference likelihood

### Key Insights
- **Most Important Features**: User-recipe compatibility scores matter most
- **Content + Collaborative**: Hybrid approach outperforms pure collaborative filtering
- **Real-time Performance**: Can score thousands of recipes instantly
- **Cold Start Handling**: Works for new users with minimal interaction data

## ğŸ“ Learning Resources

### For ML Beginners
The codebase includes extensive beginner-friendly documentation:
- **ğŸ“– Inline code comments** explain ML concepts in simple terms
- **ğŸ”§ Step-by-step workflow** methods with clear explanations
- **ğŸ’¡ Configuration system** makes customization easy to understand
- **ğŸ› ï¸ Comprehensive error handling** with helpful troubleshooting messages

## ğŸ§ª Testing and Validation

### Test the Model
```python
# Quick test
from recipe_recommender.inference.production_recipe_scorer import ProductionRecipeScorer
scorer = ProductionRecipeScorer()

# Test with sample interactions
test_interactions = [
    {"recipe_id": "100", "event_type": "Recipe Cooked", "timestamp": 1755666000}
]

result = scorer.get_user_recipe_recommendations("test_user", test_interactions)
print(f"Generated {len(result['recommendations'])} recommendations")
```

### Model Evaluation
Run the evaluation script to check model performance:
```bash
uv run python recipe_recommender/models/hybrid_gbm_recommender.py
```

## ğŸ“ˆ Monitoring and Maintenance

### Key Metrics to Monitor
- **Recommendation CTR**: Click-through rates on recommended recipes
- **Cooking Rate**: How often recommended recipes are actually cooked
- **User Engagement**: Changes in overall recipe interaction rates
- **Model Performance**: AUC, precision, recall on held-out data

### Model Refresh Schedule
- **Weekly**: Monitor performance metrics
- **Monthly**: Retrain with new interaction data
- **Quarterly**: Full evaluation and potential architecture updates

## ğŸ”® Future Enhancements

### Potential Improvements
1. **Seasonal Recommendations**: Incorporate seasonal ingredient preferences
2. **Nutritional Filtering**: Add dietary restrictions and nutrition goals
3. **Social Features**: Include recipe ratings and reviews
4. **Real-time Learning**: Online learning from user feedback
5. **Multi-objective Optimization**: Balance variety, novelty, and relevance

### Data Sources to Consider
- Recipe ratings and reviews from users
- Nutritional information for health-conscious recommendations
- Seasonal ingredient availability
- User pantry/grocery list data for ingredient-based recommendations

## ğŸ› Troubleshooting

### Common Issues

**"No model found"**
- Make sure you've run the training pipeline: `hybrid_recommendation_data_builder.py` â†’ `hybrid_gbm_recommender.py`

**"No recipe data"**  
- Verify Supabase connection: `python recipe_recommender/etl/database/supabase_config.py`
- Run data fetcher: `python recipe_recommender/etl/database/fetch_real_recipes.py`

**"Low recommendation quality"**
- Check if user has sufficient interaction history (minimum 3-5 interactions recommended)
- Verify training data quality and feature engineering
- Consider retraining with more recent data

**Performance issues**
- For very large recipe catalogs, consider adding recipe filtering by category/cuisine
- Cache user profiles for frequent requests
- Use batch scoring for multiple users

### Support
For technical issues:
1. Check the logs in each script for detailed error messages
2. Verify all dependencies are installed: `uv sync`
3. Ensure Supabase credentials are correctly set
4. Review the `real_database_summary.txt` for data quality issues

---

## ğŸ“‹ Summary

This system provides a complete solution for personalized recipe recommendations:

âœ… **Trained hybrid GBM model** with excellent performance  
âœ… **Production-ready API** for real-time recommendations  
âœ… **Comprehensive feature engineering** combining user behavior + recipe content  
âœ… **Scalable retraining pipeline** for continuous improvement  
âœ… **Clean codebase** with essential files only  

**Ready for production deployment and can serve personalized recipe recommendations at scale!** ğŸ‰